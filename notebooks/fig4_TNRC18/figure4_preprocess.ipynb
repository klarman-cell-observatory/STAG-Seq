{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41027852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script takes the Hypr-seq adata and the loom file as input\n",
    "# And output an scRNA-seq data with detailed annotations\n",
    "\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import logging\n",
    "import configparser\n",
    "import anndata\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "import argparse\n",
    "import copy\n",
    "import h5py\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Read and filter the Hypr-seq anndata\n",
    "def filter_hypr(adata, probe_level=False):\n",
    "    # Remove cells with less than 1000 UMIs per cell\n",
    "    sc.pp.filter_cells(adata, min_counts=1000)\n",
    "    # merge the probe name, making the cell by probe matrix to cell by gene matrix\n",
    "    # Splitting at the underscore to separate gene names from probe numbers\n",
    "    if not probe_level:\n",
    "        gene_names = [name.split('_')[0] for name in adata.var_names]\n",
    "    else:\n",
    "        gene_names = [name for name in adata.var_names]\n",
    "\n",
    "    # Add the gene names as a new column in the DataFrame of the .var slot\n",
    "    adata.var['gene_name'] = gene_names\n",
    "    # Convert the AnnData to a DataFrame for easier manipulation\n",
    "    adata.X = adata.X.toarray()\n",
    "    adata_df = pd.DataFrame(adata.X.T, index=adata.var_names, columns=adata.obs_names)\n",
    "\n",
    "    # Use the gene names to sum the counts\n",
    "    # Group by the new gene names and sum across columns (probes for the same gene)\n",
    "    aggregated_data = adata_df.groupby(adata.var['gene_name']).sum()\n",
    "\n",
    "    # Transpose back to original shape (samples as rows, genes as columns)\n",
    "    aggregated_data = aggregated_data.T\n",
    "\n",
    "    # Create new AnnData object with the aggregated data\n",
    "    adata_aggregated = sc.AnnData(X=aggregated_data)\n",
    "    # Copy the metadata from the original AnnData object\n",
    "    adata_aggregated.obs = adata.obs.copy()\n",
    "    # Optionally, copy over any relevant .uns data (unsupervised annotations, such as PCA, neighbors, etc.)\n",
    "    #adata_aggregated.uns = adata.uns.copy()\n",
    "\n",
    "    return adata_aggregated\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# function reads the loomfile downloaded from Tapestri portal\n",
    "def read_tapestri_H5(filename):\n",
    "    \"\"\"\n",
    "    Read data from MissionBio's formatted loom file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Path to the loom file (.loom)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    anndata.AnnData\n",
    "        An anndata object with the following layers:\n",
    "        adata.X: GATK calls\n",
    "        adata.layers['e']: reads with evidence of mutation\n",
    "        adata.layers['no_e']: reads without evidence of mutation\n",
    "    \"\"\"\n",
    "\n",
    "    with h5py.File(filename, \"r\") as file:\n",
    "        # get the variant name, amplicon, chromosome, location]\n",
    "        # import pdb; pdb.set_trace()\n",
    "        variant_names = file['assays'][\"dna_variants\"][\"ca\"]['id'][:] # binary\n",
    "        variant_names = np.array([i.decode(\"utf-8\") for i in variant_names])\n",
    "\n",
    "\n",
    "        amplicon_names = file['assays']['dna_variants']['ca']['amplicon'][:] # binary\n",
    "        amplicon_names = np.array([i.decode(\"utf-8\") for i in amplicon_names])\n",
    "\n",
    "        chromosome = file['assays']['dna_variants']['ca']['CHROM'][:] # binary\n",
    "        chromosome = np.array([i.decode(\"utf-8\") for i in chromosome])\n",
    "\n",
    "\n",
    "        location = file['assays']['dna_variants']['ca']['POS'][:]\n",
    "\n",
    "        # get the barcode\n",
    "        barcodes = file['assays']['dna_variants']['ra']['barcode'][:] # binary\n",
    "        barcodes = np.array([i.decode(\"utf-8\") for i in barcodes])\n",
    "\n",
    "        mutation_matrix = file['assays']['dna_variants']['layers']['NGT'][:,:]\n",
    "\n",
    "        adata = anndata.AnnData(X=mutation_matrix, dtype=np.int8)\n",
    "        adata.obs_names = barcodes\n",
    "        adata.var_names = variant_names\n",
    "        adata.varm[\"amplicon\"] = amplicon_names\n",
    "        adata.varm[\"chrom\"] = chromosome\n",
    "        adata.varm[\"loc\"] = location\n",
    "    file.close()\n",
    "\n",
    "    return adata\n",
    "\n",
    "\n",
    "\n",
    "# Optional function, visualize the barcode distribution\n",
    "def barcode_rank_plot(adata, minimum=0, xmax=None):\n",
    "\n",
    "    # Sum the UMIs for each cell\n",
    "    cell_umi_counts_all = adata.X.sum(axis=1)\n",
    "    cell_idxs = np.argwhere(cell_umi_counts_all > minimum)\n",
    "    cell_umi_counts = cell_umi_counts_all[cell_idxs]\n",
    "\n",
    "    # Convert to numpy array if it's not already\n",
    "    cell_umi_counts = np.array(cell_umi_counts).flatten()\n",
    "\n",
    "    # Sort the UMI counts in descending order for the rank plot\n",
    "    sorted_umi_counts = np.sort(cell_umi_counts)[::-1]\n",
    "\n",
    "    plt.figure(figsize=(5, 4), dpi=150)\n",
    "    sns.lineplot(x=range(1, len(sorted_umi_counts) + 1), y=sorted_umi_counts)\n",
    "    plt.xlabel('Barcode Rank')\n",
    "    plt.ylabel('UMI Count')\n",
    "    plt.title('Cell Barcode Rank Plot')\n",
    "    plt.yscale('log')  # Log scale for better visualization\n",
    "    plt.xscale('log') # Log scale\n",
    "    if xmax is not None:\n",
    "        plt.xlim(0, xmax)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Function for finding the intersecting barcodes between the modalities\n",
    "# We can drop the idea of mudata for simplity\n",
    "def find_intersecting_and_filter(adata_hypr, adata_h5):\n",
    "    \"\"\"\n",
    "    Find the intersecting barcode, reorder, and return new AnnData objects for both datasets.\n",
    "    \"\"\"\n",
    "    # Find intersecting barcodes\n",
    "    obs_1, obs_2 = adata_hypr.obs_names, adata_h5.obs_names\n",
    "    cmn_barcodes, idx_1, idx_2 = np.intersect1d(obs_1, obs_2, return_indices=True)\n",
    "\n",
    "    # Logging the number of barcodes\n",
    "    logger.info(f\"Found {len(obs_1)} barcodes in modality hypr seq\")\n",
    "    logger.info(f\"Found {len(obs_2)} barcodes in modality loom file\")\n",
    "    logger.info(f\"Found {len(idx_1)} intersecting barcodes\")\n",
    "\n",
    "    # Subset and reorder both datasets based on the intersecting indices\n",
    "    adata_hypr_new = adata_hypr[idx_1, :]\n",
    "    adata_h5_new = adata_h5[idx_2, :]\n",
    "\n",
    "    # # Ensure the order of barcodes is the same in both datasets\n",
    "    # adata_hypr_new = adata_hypr_new[cmn_barcodes, :]\n",
    "    # adata_h5_new = adata_h5_new[cmn_barcodes, :]\n",
    "\n",
    "    return adata_hypr_new, adata_h5_new\n",
    "    \n",
    "\n",
    "# Step 1, determine the germline mutation from the loom file\n",
    "# We envision that if certain mutation appeared too many times in the dataset\n",
    "# (e.g., more than 25% cells have the homo mutation, we call it homo germline)\n",
    "def call_germline_mutations(adata_h5, cutoff=0.25):\n",
    "\n",
    "    fraction_het = np.mean(adata_h5.X == 1, axis=0)\n",
    "    het_germline = adata_h5.var_names[fraction_het > cutoff]\n",
    "\n",
    "    fraction_hom = np.mean(adata_h5.X == 2, axis=0)\n",
    "    hom_germline = adata_h5.var_names[fraction_hom > cutoff]\n",
    "\n",
    "    return list(het_germline) + list(hom_germline)\n",
    "\n",
    "\n",
    "def call_germline_mutations_from_DNA_seq(donor1_h5, donor2_h5):\n",
    "    \"\"\"\n",
    "    Given the donor B/C dna-seq h5 file, this function extract the germline mutations    \n",
    "    \"\"\"\n",
    "\n",
    "    def call_germline_mutations_for_donor(donor1_h5, donor=\"B\"):\n",
    "        with h5py.File(donor1_h5, \"r\") as file:\n",
    "            # remove the bad amplicons\n",
    "            amplicon_names = file['assays']['dna_variants']['ca']['amplicon'][:] # binary\n",
    "            amplicon_names = np.array([i.decode(\"utf-8\") for i in amplicon_names])\n",
    "            amplicon_bad_c = [\"TAMPL86172\", 'TAMPL86171', 'TAMPL86243', 'TAMPL86176', 'TAMPL86144', 'TAMPL86221', 'TAMPL86163', 'TAMPL86186', 'TAMPL86231', \n",
    "                                'TAMPL86189', 'TAMPL86213', 'TAMPL86149', 'TAMPL86140', 'TAMPL86164', 'TAMPL86228', 'TAMPL86150', 'TAMPL86179', 'TAMPL86165', \n",
    "                                'TAMPL86240', 'TAMPL86181', 'TAMPL86183', 'TAMPL86234', 'TAMPL86126', 'TAMPL86222', 'TAMPL86191', 'TAMPL86210', 'TAMPL86167',\n",
    "                                'TAMPL86190', 'TAMPL86128', 'TAMPL86199', 'TAMPL86143', 'TAMPL86141', 'TAMPL86136', 'TAMPL86135', 'TAMPL86214', 'TAMPL86223', \n",
    "                                'TAMPL86220', 'TAMPL86207', 'TAMPL86217', 'TAMPL86129', 'TAMPL86195', 'TAMPL86185', 'TAMPL86224', 'TAMPL86173', 'TAMPL86198',\n",
    "                                'TAMPL86142', 'TAMPL86219']\n",
    "            amplicon_bad_b = [\"TAMPL86200\", \"TAMPL86172\", 'TAMPL86171', 'TAMPL86243', 'TAMPL86144', 'TAMPL86221', 'TAMPL86163', 'TAMPL86186','TAMPL86231',\n",
    "                                'TAMPL86176', 'TAMPL86140', 'TAMPL86149', 'TAMPL86179','TAMPL86213','TAMPL86189','TAMPL86234','TAMPL86150','TAMPL86165','TAMPL86190',\n",
    "                                'TAMPL86240','TAMPL86228','TAMPL86126','TAMPL86167','TAMPL86181','TAMPL86183','TAMPL86210','TAMPL86229','TAMPL86222','TAMPL86191',\n",
    "                                'TAMPL86199','TAMPL86128','TAMPL86233','TAMPL86232','TAMPL86135','TAMPL86195','TAMPL86141','TAMPL86143','TAMPL86207','TAMPL86166',]\n",
    "            \n",
    "            if donor == \"B\":\n",
    "                amplicon_bad = amplicon_bad_b\n",
    "            elif donor == \"C\":\n",
    "                amplicon_bad = amplicon_bad_c\n",
    "            \n",
    "            # List comprehension to find indices of good amplicons\n",
    "            good_indices = [index for index, amplicon in enumerate(amplicon_names) if amplicon not in amplicon_bad]\n",
    "\n",
    "            print(\"Indices of good amplicons:\", good_indices)\n",
    "            # get the variant names\n",
    "            variant_names = file['assays'][\"dna_variants\"][\"ca\"]['id'][:] # binary\n",
    "            variant_names = np.array([i.decode(\"utf-8\") for i in variant_names])\n",
    "\n",
    "            # only keep good variant\n",
    "            variant_names = variant_names[good_indices]\n",
    "\n",
    "            # get the mutation matrix\n",
    "            mutation_matrix = file['assays']['dna_variants']['layers']['NGT'][:,:]\n",
    "            assert mutation_matrix.shape[0] == 1\n",
    "            mutation_matrix = mutation_matrix[0]\n",
    "\n",
    "            # only keep the good variant\n",
    "            mutation_matrix = mutation_matrix[good_indices]\n",
    "            # determine the het mutations\n",
    "            het_donor1 = np.where(mutation_matrix == 1)\n",
    "            het_germline_donor1 = variant_names[het_donor1]\n",
    "            # hom germline mutations\n",
    "            hom_donor1 = np.where(mutation_matrix == 2)\n",
    "            hom_germline_donor1 = variant_names[hom_donor1]\n",
    "            \n",
    "            donor1_germline_mutations = list(het_germline_donor1) + list(hom_germline_donor1)\n",
    "            # import pdb; pdb.set_trace()\n",
    "            \n",
    "            file.close()\n",
    "        return donor1_germline_mutations\n",
    "    \n",
    "    donor1_germline_mutations = call_germline_mutations_for_donor(donor1_h5, \"B\")\n",
    "    donor2_germline_mutations = call_germline_mutations_for_donor(donor2_h5, \"C\")\n",
    "\n",
    "    return donor1_germline_mutations, donor2_germline_mutations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# For AAV control, we may ignore mixed cells and bystander effect\n",
    "def call_AAV_control_edits(adata_h5, config_path='IRF4.ini'):\n",
    "    \"\"\"\n",
    "    Input: Tapestri loom file and mutation configuration \n",
    "    Current we only accept 1 type of AAV control (should be a continuous region)\n",
    "    Output: All the AAV edits found in the loom file. \n",
    "\n",
    "    This function will not modify adata_h5\n",
    "    \"\"\"\n",
    "    # Read configuration settings\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_path)\n",
    "    \n",
    "    chrom_name = config.get('AAV_ACBE3', 'chrom_name')\n",
    "    start = config.getint('AAV_ACBE3', 'start')\n",
    "    end = config.getint('AAV_ACBE3', 'end')\n",
    "    variant_alleles = config.get('AAV_ACBE3', 'variant_alleles')\n",
    "    \n",
    "    # Parsing variant names\n",
    "    variant_names = np.asarray(adata_h5.var_names.values)\n",
    "    chrom = [name.split(':')[0] for name in variant_names]\n",
    "    # import pdb; pdb.set_trace()\n",
    "    loc = [int(name.split(':')[1]) for name in variant_names]\n",
    "    edit_type = [name.split(':')[2] for name in variant_names]\n",
    "\n",
    "    control_editing = []\n",
    "    complement_rule = {'C': 'G', 'G': 'C', 'A': 'T', 'T': 'A'}\n",
    "    try:\n",
    "        reverse_variant_alleles = complement_rule[variant_alleles[0]] + \"/\" + complement_rule[variant_alleles[-1]]\n",
    "    except:\n",
    "        raise ValueError(f\"The variant alleles is not supported. Current variant alleles is {variant_alleles}\")\n",
    "    # Identify control editing cells\n",
    "    for i in range(len(chrom)):\n",
    "        if chrom[i] == chrom_name and start <= loc[i] < end+1:\n",
    "            if edit_type[i] in [variant_alleles, reverse_variant_alleles]:\n",
    "                control_editing.append(variant_names[i])\n",
    "\n",
    "    return control_editing\n",
    "\n",
    "\n",
    "def call_AAV_PE4_edits(adata_h5, config_path):\n",
    "    \"\"\"\n",
    "    Input: Tapestri loom file and mutation configuration \n",
    "    Output: All the AAV edits found in the loom file. \n",
    "    \"\"\"\n",
    "    # Read configuration settings\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_path)\n",
    "    \n",
    "    chrom_name = config.get('AAVS-PE4max', 'chrom_name')\n",
    "    locus = config.getint('AAVS-PE4max', 'locus')\n",
    "    \n",
    "    \n",
    "    # Parsing variant names\n",
    "    variant_names = np.asarray(adata_h5.var_names.values)\n",
    "    chrom = [name.split(':')[0] for name in variant_names]\n",
    "    loc = [int(name.split(':')[1]) for name in variant_names]\n",
    "    edit_type = [name.split(':')[2] for name in variant_names]\n",
    "\n",
    "    pe4_editing = []\n",
    "    \n",
    "    # Identify control editing cells\n",
    "    for i in range(len(chrom)):\n",
    "        if chrom[i] == chrom_name and loc[i] == locus:\n",
    "\n",
    "            if edit_type[i] in [\"C/T\", \"C/*\", \"G/A\", \"G/*\"]:\n",
    "                pe4_editing.append(variant_names[i])\n",
    "            \n",
    "    return pe4_editing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def call_AAV_cells(adata_hypr, adata_h5, AAV_editing):\n",
    "    \"\"\"\n",
    "    Annotate the hypr adata (scRNA-seq data) by the AAV_edit found in call_AAV_edits.\n",
    "    We do not perform annotation in the function to ensure consistency\n",
    "    \"\"\"\n",
    "    all_idx = []\n",
    "    for edit in AAV_editing:\n",
    "        # get the idx of the edit we found\n",
    "        idx = adata_h5.var_names.get_loc(edit)\n",
    "        # if the value is 1/2 (hete/homo), we annotate the cell as control edit cell\n",
    "        het_idx, hom_idx = [np.flatnonzero(adata_h5.X[:, idx] == i) for i in (1, 2)]\n",
    "        AAV_edit_idx = np.concatenate([het_idx, hom_idx])\n",
    "        AAV_cells_barcode_loom = adata_h5.obs_names[AAV_edit_idx]\n",
    "        # find the AAV cells index in that of the adata_hypr\n",
    "        _, idx1, _ = np.intersect1d(adata_hypr.obs_names, AAV_cells_barcode_loom, return_indices=True)\n",
    "        all_idx.append(idx1)\n",
    "    return np.unique(np.concatenate(all_idx))\n",
    "\n",
    "def call_AAV4GPPKO_edits(adata_h5, config_path):\n",
    "    \"\"\"\n",
    "    Input: Tapestri loom file and mutation configuration \n",
    "    Current we only accept 1 type of AAV control (should be a continuous region)\n",
    "    Output: All the AAV edits found in the loom file. \n",
    "    \"\"\"\n",
    "    # Read configuration settings\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_path)\n",
    "    \n",
    "    chrom_name = config.get('AAVS4GPP-KO', 'chrom_name')\n",
    "    start = config.getint('AAVS4GPP-KO', 'start')\n",
    "    end = config.getint('AAVS4GPP-KO', 'end')\n",
    "    \n",
    "    # Parsing variant names\n",
    "    variant_names = np.asarray(adata_h5.var_names.values)\n",
    "    chrom = [name.split(':')[0] for name in variant_names]\n",
    "    loc = [int(name.split(':')[1]) for name in variant_names]\n",
    "    edit_type = [name.split(':')[2] for name in variant_names]\n",
    "\n",
    "    del_editing = []\n",
    "    \n",
    "    # Identify  editing cells\n",
    "    for i in range(len(chrom)):\n",
    "        if chrom[i] == chrom_name and start <= loc[i] < end+1:\n",
    "            # import pdb; pdb.set_trace()\n",
    "            \n",
    "            del_editing.append(variant_names[i])\n",
    "    # import pdb; pdb.set_trace()\n",
    "    return del_editing\n",
    "\n",
    "\n",
    "\n",
    "def call_TNRC18KO_edits(adata_h5, config_path):\n",
    "    \"\"\"\n",
    "    Input: Tapestri loom file and mutation configuration \n",
    "    Current we only accept 1 type of AAV control (should be a continuous region)\n",
    "    Output: All the AAV edits found in the loom file. \n",
    "    \"\"\"\n",
    "    # Read configuration settings\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_path)\n",
    "    \n",
    "    chrom_name = config.get('TNRC18-KO', 'chrom_name')\n",
    "    start = config.getint('TNRC18-KO', 'start')\n",
    "    end = config.getint('TNRC18-KO', 'end')\n",
    "    \n",
    "    # Parsing variant names\n",
    "    variant_names = np.asarray(adata_h5.var_names.values)\n",
    "    chrom = [name.split(':')[0] for name in variant_names]\n",
    "    loc = [int(name.split(':')[1]) for name in variant_names]\n",
    "    edit_type = [name.split(':')[2] for name in variant_names]\n",
    "\n",
    "    del_editing = []\n",
    "    \n",
    "    # Identify  editing cells\n",
    "    for i in range(len(chrom)):\n",
    "        if chrom[i] == chrom_name and start <= loc[i] < end+1:\n",
    "            if edit_type[i][-1] == \"*\":\n",
    "                del_editing.append(variant_names[i])\n",
    "\n",
    "    return del_editing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_nearby_variants(\n",
    "    variant_names, # List of all variant in the loom file\n",
    "    target_loc, # loci of interest\n",
    "    germline_amplicons, # List of Germline mutations \n",
    "    window_size # window size\n",
    "):\n",
    "    \"\"\"\n",
    "        Get nearby variants within a window size of the target_loc.\n",
    "        Args:\n",
    "            variant_names (list): List of variant names.\n",
    "            target_loc (str): Target loci (e.g. chr1:123456:A/G).\n",
    "            germline_amplicons (list): List of germline amplicons.\n",
    "            window_size (int): Window size.\n",
    "        Returns:\n",
    "            list: List of nearby variants.\n",
    "    \"\"\"\n",
    "    chrom_t, loc_t, _ = target_loc.split(\":\")\n",
    "    nearby_variants = []\n",
    "    # import pdb; pdb.set_trace()\n",
    "    if target_loc in germline_amplicons:\n",
    "        germline_amplicons.remove(target_loc)\n",
    "    for variant in variant_names:\n",
    "        chrom, loc, edit_type = variant.split(\":\")\n",
    "        is_valid_edit_type = not edit_type.endswith(\"*\") and re.match(\n",
    "            r\"^[A-Za-z]/[A-Za-z]$\", edit_type\n",
    "        )\n",
    "        is_not_germline = variant not in germline_amplicons\n",
    "        if (\n",
    "            chrom == chrom_t\n",
    "            and (int(loc_t) - window_size) <= int(loc) <= (int(loc_t) + window_size)\n",
    "            and is_valid_edit_type\n",
    "            and is_not_germline\n",
    "        ):\n",
    "            nearby_variants.append(variant)\n",
    "\n",
    "    return nearby_variants\n",
    "\n",
    "\n",
    "\n",
    "def plot_mutant_types(target_loc, new_matrix, mt_type, snp_name, save_path, index=\"\"):\n",
    "    \"\"\"\n",
    "    Plot the nearby genotype heatmap\n",
    "    \"\"\"\n",
    "    mutation_counts = new_matrix.apply(np.count_nonzero, axis=0)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(mutation_counts.index, mutation_counts.values)\n",
    "    for i, idx in enumerate(mutation_counts.index):\n",
    "        plt.text(\n",
    "            bars[i].get_x() + bars[i].get_width() / 2,\n",
    "            bars[i].get_height(),\n",
    "            str(mutation_counts.values[i]),\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "    if target_loc in mutation_counts.index:\n",
    "        bars[mutation_counts.index.tolist().index(target_loc)].set_color(\"r\")\n",
    "    red_patch = mpatches.Patch(color=\"red\", label=\"Target Loci\")\n",
    "    plt.legend(handles=[red_patch])\n",
    "\n",
    "    # we need to rename the target_loc to ensure we do not introduce extra path problems\n",
    "    target_loc = target_loc.replace(\"/\", \"-\")\n",
    "\n",
    "\n",
    "    plot_title = (\n",
    "        f\"Mutation Counts: {mt_type} - {target_loc} ({index}) with total cells {len(new_matrix)}\"\n",
    "    )\n",
    "    plt.title(plot_title)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"Number of Mutated Cells\")\n",
    "\n",
    "    save_index = f\"{snp_name}_{mt_type}_mutant_counts_{index}.pdf\"\n",
    "    plt.savefig(os.path.join(save_path, save_index), bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    # Plot a cluster map of matrix but cluster rows only.\n",
    "    sns.clustermap(\n",
    "        new_matrix,\n",
    "        cmap=\"YlGnBu\",\n",
    "        row_cluster=True,\n",
    "        col_cluster=False,\n",
    "        figsize=(10, 10),\n",
    "    )\n",
    "    plt.title(\n",
    "        f\"Mutation Matrix: {mt_type} - {snp_name} aka {target_loc} with shape {new_matrix.shape}\"\n",
    "    )\n",
    "    plt.xlabel(\"Variant\")\n",
    "    plt.ylabel(\"Cell Barcode\")\n",
    "    save_index = f\"{snp_name}_{mt_type}_mutant_matrix_{index}.pdf\"\n",
    "    plt.savefig(os.path.join(save_path, save_index), bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_bystander_cells(target_loc, cells, nearby_variants, adata_h5):\n",
    "    \"\"\"\n",
    "    Identify which cells have bystander editing.\n",
    "    Args:\n",
    "        target_loc (str): Target loci (e.g. chr1:123456:A/G).\n",
    "        cells (list): List of cells (that supposedly have the mutation).\n",
    "        nearby_variant: adata that includes only the nearby cells\n",
    "    Returns:\n",
    "        list: List of pure cells.\n",
    "        pd.DataFrame: New matrix.\n",
    "        pd.DataFrame: Matrix with false amplicons.\n",
    "    \"\"\"\n",
    "\n",
    "    nearby_adata = adata_h5[cells, nearby_variants].copy()\n",
    "    new_matrix = pd.DataFrame(\n",
    "        nearby_adata.X, index=nearby_adata.obs_names, columns=nearby_adata.var_names\n",
    "    )\n",
    "    # Change all 3 to 0 in the new matrix, but excluding the target loci column.\n",
    "    for col in new_matrix.columns:\n",
    "        if col != target_loc:\n",
    "            new_matrix[col] = new_matrix[col].apply(\n",
    "                lambda val: 0 if val == 3 else val\n",
    "            )\n",
    "\n",
    "    # Remove the target loci column to generate a bystander position only matrix.\n",
    "    matrix_without_target_loci = new_matrix.loc[\n",
    "        :, new_matrix.columns != target_loc\n",
    "    ].copy()\n",
    "    bystander_sum_for_every_cell = matrix_without_target_loci.sum(axis=1)\n",
    "    # Remove cells that have a row sum of 0, or there's no bystander editing.\n",
    "    matrix_without_target_loci = matrix_without_target_loci.loc[\n",
    "        bystander_sum_for_every_cell != 0\n",
    "    ]\n",
    "\n",
    "    # If there's no bystander editing, return the original cells.\n",
    "    if len(matrix_without_target_loci) == 0:\n",
    "        # Set the bystander as the empty set\n",
    "        return set(cells), set(), new_matrix\n",
    "\n",
    "    # Everything that's left is a bystander cell.\n",
    "    pure_cells = set(cells) - set(matrix_without_target_loci.index)\n",
    "    return pure_cells, set(matrix_without_target_loci.index), new_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def call_single_loci_cells(\n",
    "    target_loc, # the loci of interest\n",
    "    adata_h5, # the loom matrix to retrieve info\n",
    "    window_size, # the window size \n",
    "    germline_amplicons, # The germline mutations\n",
    "    snp_name, # the name of the loci\n",
    "    plot_path, # the path to save the figures\n",
    "):\n",
    "    \"\"\"\n",
    "    Process a single target loci. \n",
    "    We will annotate all cells that include the loci\n",
    "    The values represent the mutant type:\n",
    "        0: Background\n",
    "        1: Pure heterozygous\n",
    "        2: Heterozygous with bystander editing\n",
    "        3: Pure homozygous\n",
    "        4: Homozygous with bystander editing\n",
    "    \"\"\"\n",
    "    # Find the idx of the loci\n",
    "    idx = adata_h5.var_names.get_loc(target_loc)\n",
    "    # Annotate cells that are background, het, and hom based on the loom matrix\n",
    "    bkg_cells, het_cells, hom_cells = [\n",
    "            adata_h5.obs_names[np.flatnonzero(adata_h5.X[:, idx] == i)] for i in (0, 1, 2)\n",
    "            ]\n",
    "    # Find all nearby variant of the give loci\n",
    "    variant_names = adata_h5.var_names\n",
    "    nearby_variants = get_nearby_variants(\n",
    "            variant_names, target_loc, germline_amplicons, window_size\n",
    "    )\n",
    "\n",
    "    if target_loc == \"chr7:5397122:C/T\":\n",
    "        if 'chr7:5397121:C/T' in nearby_variants:\n",
    "            nearby_variants.remove(\"chr7:5397121:C/T\")\n",
    "\n",
    "    if target_loc == \"chr7:5397121:C/T\":\n",
    "        if 'chr7:5397122:C/T' in nearby_variants:\n",
    "            nearby_variants.remove(\"chr7:5397122:C/T\")\n",
    "\n",
    "    het_pure, het_bystander, het_matrix = process_bystander_cells(\n",
    "            target_loc, het_cells, nearby_variants, adata_h5\n",
    "    )\n",
    "    hom_pure, hom_bystander, hom_matrix = process_bystander_cells(\n",
    "            target_loc, hom_cells, nearby_variants, adata_h5\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        plot_mutant_types(target_loc, het_matrix, \"Heterozygous\", snp_name, plot_path, \"1-0\")\n",
    "        plot_mutant_types(target_loc, hom_matrix, \"Homozygous\", snp_name, plot_path, \"1-0\")\n",
    "    except:\n",
    "        print(f\"Cannot make plots for the {target_loc}\")\n",
    "\n",
    "    return list(het_bystander), list(hom_bystander), list(het_pure), list(hom_pure)\n",
    "\n",
    "    # adata_hypr.loc[hom_pure, \"genotype\"] = f\"{target_loc}_homo_pure\"\n",
    "    # adata_hypr.loc[het_pure, \"genotype\"] = f\"{target_loc}_hete_pure\"\n",
    "\n",
    "\n",
    "def annotate_cells(adata):\n",
    "    \"\"\"\n",
    "    Annotates each cell in adata.obs based on the SNP, control, and del columns, according to specified rules.\n",
    "    \n",
    "    Parameters:\n",
    "    - adata: AnnData object containing the obs DataFrame with binary columns for each condition.\n",
    "    \n",
    "    Returns:\n",
    "    - Annotations are stored in a new column 'annotation' in adata.obs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # List of condition columns, based on the presence of SNPs, control, and del columns in adata.obs\n",
    "    # snp_columns = [col for col in adata.obs.columns if any(sub in col for sub in [\"het_bystander\", \"het_pure\", \"hom_bystander\", \"hom_pure\"])]\n",
    "    snp_columns = [col for col in adata.obs.columns if any(sub in col for sub in [\"het_bystander\", \"hom_bystander\"])]\n",
    "    snp_columns += [\"Double_Het\", \"Double_Hom\", \"22_het_21_hom\", \"22_hom_21_het\", \"22_het\", \"22_hom\", \"21_hom\", \"21_het\", \"AAV4GPP_KO\"]\n",
    "    control_column = \"AAV_ACBE3\"\n",
    "    \n",
    "    def annotate_row(row):\n",
    "        # Check SNP-related rules\n",
    "        snp_active = row[snp_columns].sum()  # Count number of active SNP columns (True values)\n",
    "        \n",
    "        if snp_active > 1:  # More than one SNP column is True\n",
    "            return \"mixed\"\n",
    "        \n",
    "        if row[control_column] and snp_active == 1:  # SNP and control active\n",
    "            # Find which SNP column is active\n",
    "            snp_name = row[snp_columns][row[snp_columns] == True].index[0]\n",
    "            return \"mixed\"\n",
    "         \n",
    "        \n",
    "        if row[control_column] and snp_active == 0:  # Only control active\n",
    "            return \"AAV_ACBE3\"\n",
    "        \n",
    "        \n",
    "        if snp_active == 1:  # Single SNP active, no control or del\n",
    "            snp_name = row[snp_columns][row[snp_columns] == True].index[0]\n",
    "            return snp_name\n",
    "        \n",
    "        # If no columns are active\n",
    "        if snp_active == 0 and not row[control_column]:\n",
    "            return \"unedited\"\n",
    "        \n",
    "        # Default case, though we should not reach here\n",
    "        return \"unknown\"\n",
    "    # import pdb; pdb.set_trace()\n",
    "    # Apply the annotation function to each row in a vectorized manner\n",
    "    adata.obs['genotype_annotation'] = adata.obs.apply(annotate_row, axis=1)\n",
    "\n",
    "\n",
    "def call_donor_dtype(adata_h5, unique_B, unique_C):\n",
    "    \"\"\"\n",
    "    Use the unique germline muations to understand the cell donors\n",
    "    \"\"\"\n",
    "    \n",
    "    adata_h5_subset_B_mutation = adata_h5[:, adata_h5.var_names.isin(unique_B)]\n",
    "    adata_h5_subset_C_mutation = adata_h5[:, adata_h5.var_names.isin(unique_C)]\n",
    "    \n",
    "    adata_h5_subset_B_mutation.X[adata_h5_subset_B_mutation.X==3] = 0 \n",
    "    adata_h5_subset_C_mutation.X[adata_h5_subset_C_mutation.X==3] = 0\n",
    "    \n",
    "    adata_h5_subset_B_mutation.X[adata_h5_subset_B_mutation.X==2] = 1\n",
    "    adata_h5_subset_C_mutation.X[adata_h5_subset_C_mutation.X==2] = 1\n",
    "\n",
    "    B_mutation_sum = adata_h5_subset_B_mutation.X.sum(axis=1)\n",
    "    C_mutation_sum = adata_h5_subset_C_mutation.X.sum(axis=1)\n",
    "\n",
    "    B_prob = B_mutation_sum/len(unique_B)\n",
    "    C_prob = C_mutation_sum/len(unique_C)\n",
    "\n",
    "    donor = np.array([\"Donor B\"] * len(adata_h5))\n",
    "    # import pdb; pdb.set_trace()\n",
    "    donor[B_prob<C_prob] = \"Donor C\"\n",
    "\n",
    "    return donor\n",
    "\n",
    "\n",
    "\n",
    "def annotate_genotype(adata_h5, \n",
    "                    adata_hypr, \n",
    "                    config_path,\n",
    "                    save_path=\"./\",\n",
    "                    plot_path=\"./\"):\n",
    "    \"\"\"\n",
    "    Annotate the adata_hypr, such that in the adata_hypr.obs, we have:\n",
    "    Homo pure for SNP 1, 2, 3, …\n",
    "    Homo bystander for SNP 1,2, 3, …\n",
    "    Hete pure for SNP 1, 2, 3, …\n",
    "    Hete bystander for SNP 1, 2, 3…\n",
    "    Mixed cells\n",
    "    AAVs: AAV_control, AAV_del\n",
    "    Unedited. \n",
    "    \"\"\"\n",
    "\n",
    "    # Perform the annotation step. We need:\n",
    "    # 1. Determine the germline mutations\n",
    "    # 2. Annotate the AAV_control cells\n",
    "    # 3. Annotate the AAV_del_control cells\n",
    "    # 4. For each SNP we are interested in, find if it has bystander effect\n",
    "    # 5. Determine the bystander mutations\n",
    "    # 6.  Annotate all mixed cells. For example, for 2 SNPs we are interested in, \n",
    "    #  if they are co-edited, we need to count the number. We need to annotate it as mixed.\n",
    "    \n",
    "\n",
    "    # Step 1, determine the germline mutations\n",
    "    germline_amplicons = call_germline_mutations(adata_h5, cutoff=0.25)\n",
    "\n",
    "    # Step 2, annotate the AAV_control cells\n",
    "    # 2.1 Find the control editing locis \n",
    "    \n",
    "    AAV_control_editing = call_AAV_control_edits(adata_h5, config_path=config_path)\n",
    "    # 2.2 Add a column to the adata_hypr obs and then perform the annotation only here\n",
    "    adata_hypr.obs[\"AAV_ACBE3\"] = False\n",
    "    AAV_control_cell_idx = call_AAV_cells(adata_hypr, adata_h5, AAV_editing=AAV_control_editing)\n",
    "    adata_hypr.obs.iloc[AAV_control_cell_idx, adata_hypr.obs.columns.get_loc(\"AAV_ACBE3\")] = True\n",
    "\n",
    "\n",
    "    # Step 3, annotate the AAVS4GPP-KO\n",
    "    # 3.1 Find the del editing locis\n",
    "    AAV4GPPKO = call_AAV4GPPKO_edits(adata_h5, config_path=config_path)\n",
    "    # 3.2 Add a column to the adata_hypr and then perform the annotation only here\n",
    "    adata_hypr.obs[\"AAV4GPP_KO\"] = False\n",
    "    AAV_del_cell_idx = call_AAV_cells(adata_hypr, adata_h5, AAV_editing=AAV4GPPKO)\n",
    "    adata_hypr.obs.iloc[AAV_del_cell_idx, adata_hypr.obs.columns.get_loc(\"AAV4GPP_KO\")] = True\n",
    "\n",
    "\n",
    "    # Step 3.5, annotate the AAVS4GPP-KO\n",
    "    # 3.6 Find the del editing locis\n",
    "    # TNRC18_KO = call_TNRC18KO_edits(adata_h5, config_path=config_path)\n",
    "    # import pdb; pdb.set_trace()\n",
    "    # # 3.7 Add a column to the adata_hypr and then perform the annotation only here\n",
    "    # adata_hypr.obs[\"TNRC18_KO\"] = False\n",
    "    # AAV_del_cell_idx = call_AAV_cells(adata_hypr, adata_h5, AAV_editing=TNRC18_KO)\n",
    "    # adata_hypr.obs.iloc[AAV_del_cell_idx, adata_hypr.obs.columns.get_loc(\"TNRC18_KO\")] = True\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "\n",
    "    # Step 4/5, Enumerate all other variants we are interested in\n",
    "    # Initialize the config parser\n",
    "    config = configparser.ConfigParser()\n",
    "    # Read the config file\n",
    "    config.read(config_path)\n",
    "    # Retrieve and return all section names\n",
    "    sections = config.sections()\n",
    "    exclude_sections = [\"AAV_ACBE3\", \"AAVS4GPP-KO\", \"TNRC18-KO\"]\n",
    "    SNPs = [section for section in sections if section not in exclude_sections]\n",
    "\n",
    "    # Each snp is the section name we defined in the config file\n",
    "    # Perform the annotation here\n",
    "    annotation = [\"het_bystander\", \"het_pure\", \"hom_bystander\", \"hom_pure\"]\n",
    "    # SNPs = [\"IRF4-rs9392504\"]\n",
    "    # import pdb; pdb.set_trace()\n",
    "    for snp in SNPs:\n",
    "        chrom_name = config.get(snp, 'chrom_name')\n",
    "        locus = config.getint(snp, 'locus')\n",
    "        alleles = config.get(snp, 'variant_alleles')\n",
    "        complement_rule = {'C': 'G', 'G': 'C', 'A': 'T', 'T': 'A'}\n",
    "        try:\n",
    "            complement_variant_alleles = complement_rule[alleles[0]] + \"/\" + complement_rule[alleles[-1]]\n",
    "        except:\n",
    "            raise ValueError(f\"The variant alleles is not supported. Current variant alleles is {alleles}\")\n",
    "        # Transfer back to the original version\n",
    "        target_loc = \":\".join([chrom_name, str(locus), alleles])\n",
    "        complement_target_loc = \":\".join([chrom_name, str(locus), complement_variant_alleles])\n",
    "        \n",
    "        # Find which allele is the one we want, the original version or the complement one\n",
    "        if target_loc in adata_h5.var_names:\n",
    "            target_loc = target_loc\n",
    "        elif complement_target_loc in adata_h5.var_names:\n",
    "            target_loc = complement_target_loc\n",
    "        else:\n",
    "            print(f\"Both the mutation {target_loc} and the reversed one {complement_target_loc} is not found in the loom file\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        # Get the index of the cells\n",
    "        het_bystander, hom_bystander, het_pure, hom_pure = call_single_loci_cells(target_loc, adata_h5, window_size=10, \n",
    "            germline_amplicons=germline_amplicons, snp_name = snp, plot_path=plot_path)\n",
    "        \n",
    "\n",
    "        for i, idx_i in enumerate([het_bystander, het_pure, hom_bystander, hom_pure]):\n",
    "            adata_hypr.obs[f\"{snp}_{annotation[i]}\"] = False\n",
    "            adata_hypr.obs.loc[idx_i, f\"{snp}_{annotation[i]}\"] = True\n",
    "\n",
    "        # adata_hypr.obs[f\"{snp}\"] = adata_hypr.obs[f\"{snp}_het_all\"] | adata_hypr.obs[f\"{snp}_hom_all\"]\n",
    "    # import pdb; pdb.set_trace()\n",
    "\n",
    "    # Step 6.5, cross annotate the double Het, double hom, 21Het + 22 Hom, 21 Hom + 22 Het, 21 Het, 21 Hom, 22 Het, 22 Hom, \n",
    "    adata_hypr.obs[\"Double_Het\"] = adata_hypr.obs['TNRC18-rs748670681_het_pure'] & adata_hypr.obs['TNRC18-21CT_het_pure']\n",
    "    adata_hypr.obs[\"Double_Hom\"] = adata_hypr.obs['TNRC18-rs748670681_hom_pure'] & adata_hypr.obs['TNRC18-21CT_hom_pure']\n",
    "    adata_hypr.obs[\"22_het_21_hom\"] = adata_hypr.obs['TNRC18-rs748670681_het_pure'] & adata_hypr.obs['TNRC18-21CT_hom_pure']\n",
    "    adata_hypr.obs[\"22_hom_21_het\"] = adata_hypr.obs['TNRC18-rs748670681_hom_pure'] & adata_hypr.obs['TNRC18-21CT_het_pure']\n",
    "    adata_hypr.obs[\"22_het\"] = adata_hypr.obs['TNRC18-rs748670681_het_pure'] & (~adata_hypr.obs['TNRC18-21CT_het_pure']) & (~adata_hypr.obs['TNRC18-21CT_hom_pure'])\n",
    "    adata_hypr.obs[\"22_hom\"] = adata_hypr.obs['TNRC18-rs748670681_hom_pure'] & (~adata_hypr.obs['TNRC18-21CT_het_pure']) & (~adata_hypr.obs['TNRC18-21CT_hom_pure'])\n",
    "    adata_hypr.obs[\"21_het\"] = adata_hypr.obs['TNRC18-21CT_het_pure'] & (~adata_hypr.obs['TNRC18-rs748670681_het_pure']) & (~adata_hypr.obs['TNRC18-rs748670681_hom_pure'])\n",
    "    adata_hypr.obs[\"21_hom\"] = adata_hypr.obs['TNRC18-21CT_hom_pure'] & (~adata_hypr.obs['TNRC18-rs748670681_het_pure']) & (~adata_hypr.obs['TNRC18-rs748670681_hom_pure'])\n",
    "\n",
    "    # Step 7, for the cells that has genotypes, we need to ensure that they are not mixed cells\n",
    "    annotate_cells(adata_hypr)\n",
    "    # import pdb; pdb.set_trace()\n",
    "    return adata_hypr, adata_h5\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Create the parser\n",
    "    parser = argparse.ArgumentParser(description=\"Filter, Intersect and Annotate \\\n",
    "     the genotype information to the phenotype RNA-seq count matrix\")\n",
    "    \n",
    "    # Add arguments for file paths\n",
    "    parser.add_argument('--tapestri_path', type=str, required=True, help='The path to the h5 file -- genotype')\n",
    "    parser.add_argument('--hypr_path', type=str, required=True, help='The path to the hypr file -- phenotype')\n",
    "    parser.add_argument('--config_path', type=str, required=True, help='The path to the variant configuration file')\n",
    "    parser.add_argument('--save_path', type=str, required=True, help='The path to save annotated anndata')\n",
    "    parser.add_argument('--plot_path', type=str, required=True, help='The path to save genotype clustermap figure')\n",
    "    parser.add_argument('--probe_level', type=int, required=True, help=\"1 for probe level matrix, other numbers for gene_level\")\n",
    "    \n",
    "    # Parse the arguments\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "\n",
    "    # read the data and set the config path\n",
    "    adata_h5 = read_tapestri_H5(args.tapestri_path)\n",
    "    adata_hypr = sc.read(args.hypr_path)\n",
    "    \n",
    "    probe_level = (args.probe_level==1)\n",
    "\n",
    "    adata_hypr = filter_hypr(adata_hypr, probe_level=probe_level)\n",
    "\n",
    "    config_path = args.config_path\n",
    "    save_path = args.save_path\n",
    "    plot_path = args.plot_path\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        # Create the directory, including any intermediate directories\n",
    "        os.makedirs(save_path)\n",
    "    if not os.path.exists(plot_path):\n",
    "        # Create the directory, including any intermediate directories\n",
    "        os.makedirs(plot_path)\n",
    "\n",
    "    # filter and intersect between hypr matrix and loom matrix\n",
    "    adata_hypr, adata_h5 = find_intersecting_and_filter(adata_hypr, adata_h5)\n",
    "    # import pdb; pdb.set_trace()\n",
    "    # Annotate the filtered data\n",
    "    adata_hypr, adata_h5 = annotate_genotype(adata_h5=adata_h5, adata_hypr=adata_hypr, config_path=config_path, save_path=save_path, plot_path=plot_path)\n",
    "    if probe_level:\n",
    "        hypr_name = f\"{save_path}/Annotated_phenotype_hypr_seq_probe.h5ad\"\n",
    "    else:\n",
    "        hypr_name = f\"{save_path}/Annotated_phenotype_hypr_seq.h5ad\"\n",
    "    sc.write(hypr_name, adata_hypr)\n",
    "    sc.write(f\"{save_path}/genotype_loom.h5ad\", adata_h5)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # the conig is TNRC18.ini\n",
    "    # The Tapestri h5 file is Th1_TNRC18.dna.h5\n",
    "    # The hypr file is Th1_TNRC18.h5ad\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd70ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute DEGs\n",
    "\n",
    "def compute_deg(input_path, save_path):\n",
    "    adata = sc.read(input_path)\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    adata.obs['genotype_annotation'] = adata.obs[\"genotype_annotation\"].astype('category')\n",
    "    compute_pairwise_degs_all(adata, save_path)\n",
    "\n",
    "def compute_marker_genes_and_plot(adata, condition_1, condition_2, task_name=\"\"):\n",
    "    \"\"\"\n",
    "    We need to ensure that the condition_2 is the control case. Otherwise, the \n",
    "    saved parameters/values may not so reliable.\n",
    "    \"\"\"\n",
    "    \n",
    "    # assert condition_2 in [\"AAV_control\", \"unedited\", \"AAV_del\"]\n",
    "    # import pdb; pdb.set_trace()\n",
    "    filtered_adata = adata[(adata.obs[\"genotype_annotation\"]==condition_1) | (adata.obs[\"genotype_annotation\"]==condition_2)]\n",
    "\n",
    "    filtered_adata.obs['genotype_annotation'] = filtered_adata.obs['genotype_annotation'].astype('category')\n",
    "    # import pdb; pdb.set_trace()\n",
    "    sc.tl.rank_genes_groups(filtered_adata, \"genotype_annotation\", method=\"wilcoxon\")\n",
    "    # sc.pl.rank_genes_groups(filtered_adata, n_genes=25, sharey=False, save=f\"{cell_type}_{condition_1}_VS_{condition_2}.png\")\n",
    "\n",
    "    # sc.pl.rank_genes_groups_dotplot(filtered_adata, save=f\"{cell_type}_{condition_1}_VS_{condition_2}.png\")\n",
    "    p_val = filtered_adata.uns[\"rank_genes_groups\"][\"pvals_adj\"][condition_1]\n",
    "    log_fc = filtered_adata.uns[\"rank_genes_groups\"][\"logfoldchanges\"][condition_1]\n",
    "    gene_names = filtered_adata.uns[\"rank_genes_groups\"][\"names\"][condition_1]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'gene_name': gene_names,\n",
    "        f'{task_name}_{condition_1}_VS_{condition_2}_log_fc': log_fc,\n",
    "        f'{task_name}_{condition_1}_VS_{condition_2}_p_val': p_val\n",
    "    })\n",
    "    df = df.sort_values(\"gene_name\")\n",
    "    df = df.set_index(\"gene_name\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_pairwise_degs_all(adata, save_path):\n",
    "\n",
    "    all_genotypes = np.unique(adata.obs[\"genotype_annotation\"])\n",
    "    exclude_genotype = [\"AAV_ACBE3\", \"mixed\", \"unedited\", \"unknown\"]\n",
    "    all_genotypes = [i for i in all_genotypes if i not in exclude_genotype]\n",
    "\n",
    "    \n",
    "    all_dfs_subset = []\n",
    "    # subset = adata[(adata.obs[\"Donor_type\"]==donor_type) & (adata.obs[\"cell_type\"]==cell_type)]\n",
    "\n",
    "\n",
    "    all_genotypes = np.unique(adata.obs[\"genotype_annotation\"])\n",
    "    exclude_genotype = [\"AAV_ACBE3\", \"mixed\", \"unedited\", \"unknown\"]\n",
    "    all_genotypes = [i for i in all_genotypes if i not in exclude_genotype]\n",
    "\n",
    "\n",
    "    for cond1 in all_genotypes:\n",
    "        if (adata.obs[\"genotype_annotation\"] == cond1).sum()<5:\n",
    "            continue\n",
    "        for cond2 in [\"AAV_ACBE3\"]:\n",
    "            result_df = compute_marker_genes_and_plot(adata, condition_1=cond1, condition_2=cond2, task_name=f\"all\")\n",
    "            all_dfs_subset.append(result_df)\n",
    "    \n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        # Create the directory, including any intermediate directories\n",
    "        os.makedirs(save_path)\n",
    "    final_subset = pd.concat(all_dfs_subset, axis=1)\n",
    "    final_subset.to_csv(f\"{save_path}/genotype_pairwise_probe_deg.csv\")\n",
    "\n",
    "    \n",
    "compute_deg(input_path = \"/mnt/data/project/25_02_15_stag_analysis/merge_annotate_result/TNRC18_Th1/Annotated_phenotype_hypr_seq_probe.h5ad\",\n",
    "    save_path=\"/mnt/data/project/25_02_15_stag_analysis/analysis_result/TNRC18_Th1/probe_deg\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
